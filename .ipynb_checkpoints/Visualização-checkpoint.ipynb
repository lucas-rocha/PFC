{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecionando ego e carregando as matrizes\n",
    "\n",
    "Matrizes  \n",
    "X: termos x documentos  \n",
    "U: termos x tópicos  \n",
    "V: tópicos x documetos  \n",
    "\n",
    "X = U * V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "ego = '1571966246'\n",
    "\n",
    "folder_X = \"X/\"\n",
    "folder_U = \"U/\"\n",
    "folder_V = \"V/\"\n",
    "\n",
    "# Carregando matriz X\n",
    "file = folder_X + ego + '.txt'\n",
    "f = open(file, 'r')\n",
    "\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "n_documentos = len(lines[0].split())\n",
    "n_termos = len(lines)\n",
    "\n",
    "X = []\n",
    "\n",
    "for i in range(0, n_termos):\n",
    "    X.append([])\n",
    "    colunas = lines[i].split()\n",
    "    for j in range(0, n_documentos):\n",
    "        X[i].append(int(colunas[j]))\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "# Carregando matriz U\n",
    "file = folder_U + ego + '.txt'\n",
    "f = open(file, 'r')\n",
    "\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "n_topicos = len(lines[0].split())\n",
    "\n",
    "U = []\n",
    "\n",
    "for i in range(0, n_termos):\n",
    "    U.append([])\n",
    "    colunas = lines[i].split()\n",
    "    for j in range(0, n_topicos):\n",
    "        U[i].append(float(colunas[j]))\n",
    "\n",
    "U = np.array(U)\n",
    "\n",
    "# Carregando matriz V\n",
    "file = folder_V + ego +'.txt'\n",
    "f = open(file, 'r')\n",
    "\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "V = []\n",
    "\n",
    "for i in range(0, n_topicos):\n",
    "    V.append([])\n",
    "    colunas = lines[i].split()\n",
    "    for j in range(0, n_documentos):\n",
    "        V[i].append(float(colunas[j]))\n",
    "\n",
    "V = np.array(V)\n",
    "\n",
    "# Importanto dicionario de termos (mapeamento indice -> termo)\n",
    "import json\n",
    "file = 'Indices de Termos/' + ego + '.json'\n",
    "f = open(file, 'r')\n",
    "line = f.readline()\n",
    "f.close()\n",
    "dic_termos = json.loads(line)\n",
    "\n",
    "# Importando documentos\n",
    "file = 'Documentos Finais/' + ego + '.txt'\n",
    "f = open(file, 'r')\n",
    "\n",
    "documentos = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tópicos e termos\n",
    "\n",
    "Visualização dos Tópicos e seus K termos mais relevantes através da matriz U. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tópico 0: FAMILY  LOSE  FILM  NIMOY  LEONARD  MISS  2653579569  AGO  WORLD  256395904  \n",
      "Tópico 1: LIVESTREAM  EDT  4  PM  PDT  SATURDAY  7  30  MOVE  WEEK  \n",
      "Tópico 2: 2016  LEAVE  CARRIE  FISHER  GLENN  JOHN  ASTRONAUT  GREAT  FELT  VOICE  \n",
      "Tópico 3: FOUNDRY  MISSIONS  SEASON  REMINDER  AUTHOR  3900315567  WORK  ROUNDTABLE  WEEKEND  1154383844  \n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "Ut = U.T\n",
    "\n",
    "for topic, vector in enumerate(Ut):\n",
    "    termos = ''\n",
    "    aux = vector\n",
    "    for i in range(0,K):\n",
    "        index = np.argmax(aux)\n",
    "        valor = aux[index]\n",
    "        aux = np.delete(aux, index)\n",
    "        valor = list(vector).index(valor)\n",
    "        termos += dic_termos[str(valor)] + '  '\n",
    "    \n",
    "    print('Tópico ' + str(topic) + ': ' + termos)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentos e tópicos\n",
    "\n",
    "Visualização da classificação de cada documento através da matriz V. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando classificacao\n",
    "Vt = V.T\n",
    "\n",
    "classificacao = []\n",
    "\n",
    "for d in Vt:\n",
    "    t = np.argmax(d)\n",
    "    classificacao.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 70), (0, 66), (2, 53), (1, 13)]\n"
     ]
    }
   ],
   "source": [
    "# Quantidade de documentos classificados por tópico\n",
    "import collections\n",
    "from operator import itemgetter\n",
    "\n",
    "contador = collections.Counter(classificacao)\n",
    "contador\n",
    "\n",
    "print(sorted(contador.items(), key = itemgetter(1), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PICARD TIP PICK \n",
      "\n",
      "14851290 STOP THINGS \n",
      "\n",
      "1 SPECIAL \n",
      "\n",
      "RT AGREE TIME \n",
      "\n",
      "15354952 HAPPEN HAPPEN \n",
      "\n",
      "DROP STOP HATE \n",
      "\n",
      "DONALD TRUMP \n",
      "\n",
      "851253492 \n",
      "\n",
      "3900315567 REMINDER START \n",
      "\n",
      "1154383844 2016 BACK GUEST \n",
      "\n",
      "3900315567 SPECIAL FOUNDRY MISSIONS \n",
      "\n",
      "3900315567 FOUNDRY BACK TOMORROW NOTE MISSIONS BREAK \n",
      "\n",
      "851253492 9 \n",
      "\n",
      "15354952 \n",
      "\n",
      "237845487 TRUMP TRUMP TRUMP STEAL ELECTION \n",
      "\n",
      "TRUMP WORK \n",
      "\n",
      "3900315567 NOTE INCOMING ELECTION RESULT LOW \n",
      "\n",
      "BREAK 1 CAPTAIN \n",
      "\n",
      "1154383844 LIVE MINUTES PLAY EPISODE \n",
      "\n",
      "GUEST STO EXPLORE \n",
      "\n",
      "1154383844 FOUNDRY ROUNDTABLE GUEST \n",
      "\n",
      "REMEMBER BACK DAY FOUNDRY WEEKEND BACK \n",
      "\n",
      "FOUNDRY SPOTLIGHT HONOUR \n",
      "\n",
      "3 \n",
      "\n",
      "ENTERPRISE BRING \n",
      "\n",
      "38424904 START MINUTES LATE TIME \n",
      "\n",
      "541460537 HAPPY 4TH FRIENDS \n",
      "\n",
      "FOUNDRY TIP MISSION CRYPTIC MISSIONS \n",
      "\n",
      "703928022 BLOG DROP INCOMING HATE \n",
      "\n",
      "1154383844 EPISODE GUEST \n",
      "\n",
      "541460537 WORK WORK AMAZE YEARS FUN FILL YEARS \n",
      "\n",
      "541460537 WORK WORK AMAZE YEARS FUN FILL YEARS \n",
      "\n",
      "541460537 WORK WORK AMAZE YEARS FUN FILL YEARS \n",
      "\n",
      "541460537 WORK WORK AMAZE YEARS FUN FILL YEARS \n",
      "\n",
      "541460537 FOUNDRY AUTHOR VOICE ACTORS MAKE WONDERFUL YEARS \n",
      "\n",
      "38424904 PHOTONOMY SERIES \n",
      "\n",
      "MAKE DONALD TRUMP RT 8 \n",
      "\n",
      "703928022 BRING FOUNDRY SERIES PHOTONOMY \n",
      "\n",
      "1154383844 REMINDER AUTHOR WEEKEND WORK MISSIONS SEASON 11 \n",
      "\n",
      "LEETA TOMORROW \n",
      "\n",
      "1154383844 FOUNDRY ROUNDTABLE \n",
      "\n",
      "1154383844 WEEK EPISODE START WORK LIVE MISSION \n",
      "\n",
      "1154383844 FOUNDRY ROUNDTABLE \n",
      "\n",
      "541460537 FOUNDRY MISSION LIVE FOUNDRY FIND REVIEW \n",
      "\n",
      "MAKE \n",
      "\n",
      "MISSION PLAY TOP 3 MISSION \n",
      "\n",
      "SPOCK BACK TIME \n",
      "\n",
      "237845487 PHOTO CHANGE \n",
      "\n",
      "FOUNDRY MISSION PARTY YEARS \n",
      "\n",
      "CRYPTIC FINEST WORK MOVE HAPPY \n",
      "\n",
      "PLAY \n",
      "\n",
      "STEAL \n",
      "\n",
      "LOW MEN \n",
      "\n",
      "ENTERPRISE \n",
      "\n",
      "1154383844 EPISODE VOYAGER EXPLORE GUEST \n",
      "\n",
      "14851290 \n",
      "\n",
      "1154383844 WEEK BRING MISSION VALLEY SHADOW 3 ENJOY \n",
      "\n",
      "1041128100 FIND \n",
      "\n",
      "1041128100 FOUNDRY VALLEY SHADOW TIME PLAY \n",
      "\n",
      "HAPPEN CHANGE HAPPEN \n",
      "\n",
      "541460537 FUN \n",
      "\n",
      "204832963 MAKE \n",
      "\n",
      "541460537 HEY FOUNDRY SPOTLIGHT REVIEW \n",
      "\n",
      "1154383844 FOUNDRY ROUNDTABLE EPISODE CHANGE SPECIAL GUEST \n",
      "\n",
      "204832963 9 11 CHANGE AMERICAN LIFE \n",
      "\n",
      "130491582 TIME SPOCK \n",
      "\n",
      "14851290 \n",
      "\n",
      "237845487 \n",
      "\n",
      "450514707 BIG MAKE 4TH ANNIVERSARY SPECIAL \n",
      "\n",
      "703928022 REVIEW SEASON 8 WEEK FOUNDRY ROUNDTABLE \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Documentos classificados com o tópico k\n",
    "k = 3\n",
    "\n",
    "for i, j in enumerate(classificacao):\n",
    "    if j == k:\n",
    "        print(documentos[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 2653579569 YEARS AGO TODAY FAMILY WORLD LOSE FILM LEONARD NIMOY MISS \n",
      "\n",
      "3 - 3900315567 SPECIAL FOUNDRY MISSIONS \n",
      "\n",
      "2 - 86985177 JOIN STAR MOURN LOSS CARRIE FISHER PEACE \n",
      "\n",
      "2 - FELT GREAT FORCE VOICE 2016 LEAVE CARRIE FISHER \n",
      "\n",
      "2 - 15443224 HAPPY BIRTHDAY GREAT BIRTHDAY FRIEND LEAVE \n",
      "\n",
      "3 - 3900315567 FOUNDRY BACK TOMORROW NOTE MISSIONS BREAK \n",
      "\n",
      "2 - 541460537 RETWEET CHANCE WIN CHRISTMAS 2016 WINNER \n",
      "\n",
      "2 - LEAVE ASTRONAUT YRS JOHN GLENN RIP 2016 \n",
      "\n",
      "2 - 43342529 HEY BLOG POST HONOR JOHN GLENN AMERICAN ASTRONAUT \n",
      "\n",
      "0 - 15443224 LOSE FRIENDS MISS \n",
      "\n",
      "3 - 3900315567 NOTE INCOMING ELECTION RESULT LOW \n",
      "\n",
      "3 - 1154383844 FOUNDRY ROUNDTABLE GUEST \n",
      "\n",
      "3 - REMEMBER BACK DAY FOUNDRY WEEKEND BACK \n",
      "\n",
      "1 - 1154383844 HEY MOVE WEEK LIVESTREAM SATURDAY 7 EDT 4 30 PM PDT \n",
      "\n",
      "0 - 256395904 LOSE FAMILY FILM TALENTED MAN ANTON YELCHIN \n",
      "\n",
      "3 - FOUNDRY TIP MISSION CRYPTIC MISSIONS \n",
      "\n",
      "0 - 168201257 HAPPY CAPTAIN PICARD DAY JEAN LUC PICARD FINEST \n",
      "\n",
      "1 - 1154383844 START LATE TONIGHT 30 MINUTES JOIN \n",
      "\n",
      "1 - 1154383844 30 MINUTES SPECIAL SATURDAY LIVESTREAM JOIN \n",
      "\n",
      "2 - 15443224 HOPE HONOR TREK FAN LLAP \n",
      "\n",
      "3 - 541460537 WORK WORK AMAZE YEARS FUN FILL YEARS \n",
      "\n",
      "3 - 541460537 WORK WORK AMAZE YEARS FUN FILL YEARS \n",
      "\n",
      "3 - 541460537 WORK WORK AMAZE YEARS FUN FILL YEARS \n",
      "\n",
      "3 - 541460537 WORK WORK AMAZE YEARS FUN FILL YEARS \n",
      "\n",
      "3 - 541460537 FOUNDRY AUTHOR VOICE ACTORS MAKE WONDERFUL YEARS \n",
      "\n",
      "1 - 30 YRS AGO TODAY 7 DIE HONOUR \n",
      "\n",
      "3 - 703928022 BRING FOUNDRY SERIES PHOTONOMY \n",
      "\n",
      "2 - 86985177 RODDENBERRY DOOHAN STAR TREK HISTORY ACTORS \n",
      "\n",
      "3 - 1154383844 REMINDER AUTHOR WEEKEND WORK MISSIONS SEASON 11 \n",
      "\n",
      "1 - 1154383844 MOVE WEEK LIVESTREAM 7 30 PM EDT 4 30 PM PDT \n",
      "\n",
      "3 - 1154383844 WEEK EPISODE START WORK LIVE MISSION \n",
      "\n",
      "3 - 541460537 FOUNDRY MISSION LIVE FOUNDRY FIND REVIEW \n",
      "\n",
      "0 - MAN LEONARD NIMOY TOP \n",
      "\n",
      "0 - 256395904 VOYAGER 20 YEARS AGO TODAY \n",
      "\n",
      "3 - 1154383844 WEEK BRING MISSION VALLEY SHADOW 3 ENJOY \n",
      "\n",
      "3 - 1041128100 FOUNDRY VALLEY SHADOW TIME PLAY \n",
      "\n",
      "3 - 1154383844 FOUNDRY ROUNDTABLE EPISODE CHANGE SPECIAL GUEST \n",
      "\n",
      "0 - TODAY DAY FRIENDS LIVE LONG PROSPER _ \n",
      "\n",
      "0 - 256395904 HAPPY BIRTHDAY LEONARD NIMOY \n",
      "\n",
      "2 - 66884558 LATE PARTY TODAY LATE GREAT BIRTHDAY DOOHAN \n",
      "\n",
      "2 - 237845487 BIG THEORY LEAVE LEAVE \n",
      "\n",
      "3 - 703928022 REVIEW SEASON 8 WEEK FOUNDRY ROUNDTABLE \n",
      "\n",
      "20.792079207920793\n"
     ]
    }
   ],
   "source": [
    "contador = 0\n",
    "alpha = 0.2\n",
    "for i, d in enumerate(Vt):\n",
    "    t = np.argmax(d)\n",
    "    if d[t] > alpha:\n",
    "        print(str(t) + ' - ' + documentos[i])\n",
    "        contador+=1\n",
    "print(contador*100/n_documentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 202)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X.shape\n",
    "#U.shape\n",
    "V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "V = np.random.rand(n_topicos, n_documentos)\n",
    "model = NMF(n_components=n_topicos, init='custom', random_state=0)\n",
    "W = model.fit_transform(X, W=U, H=V)\n",
    "\n",
    "\n",
    "output = open(ego + '.txt', 'w+')\n",
    "\n",
    "for i in range(0, len(W)):\n",
    "    for j in range(0, len(W[0])):\n",
    "        output.write(str(W[i][j]) + ' ')\n",
    "    output.write('\\n')\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nimfa\n",
    "\n",
    "nmf = nimfa.Nmf(X, seed=None, W = U, H = V)\n",
    "nmf_fit = nmf()\n",
    "\n",
    "W = nmf_fit.basis()\n",
    "\n",
    "output = open(ego + '.txt', 'w+')\n",
    "\n",
    "for i in range(0, len(W)):\n",
    "    for j in range(0, len(W[0])):\n",
    "        output.write(str(W[i][j]) + ' ')\n",
    "    output.write('\\n')\n",
    "output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
